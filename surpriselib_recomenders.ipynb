{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Testing surprise lib recomenders"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Setup"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install surprise==0.1",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting surprise==0.1\n  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\nCollecting scikit-surprise (from surprise==0.1)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/fc/cd4210b247d1dca421c25994740cbbf03c5e980e31881f10eaddf45fdab0/scikit-surprise-1.0.6.tar.gz (3.3MB)\n\u001b[K    100% |████████████████████████████████| 3.3MB 193kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: joblib>=0.11 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from scikit-surprise->surprise==0.1) (0.12.5)\nRequirement already satisfied: numpy>=1.11.2 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from scikit-surprise->surprise==0.1) (1.14.6)\nRequirement already satisfied: scipy>=1.0.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from scikit-surprise->surprise==0.1) (1.1.0)\nRequirement already satisfied: six>=1.10.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from scikit-surprise->surprise==0.1) (1.11.0)\nBuilding wheels for collected packages: scikit-surprise\n  Building wheel for scikit-surprise (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/ec/c0/55/3a28eab06b53c220015063ebbdb81213cd3dcbb72c088251ec\nSuccessfully built scikit-surprise\nInstalling collected packages: scikit-surprise, surprise\nSuccessfully installed scikit-surprise-1.0.6 surprise-0.1\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now, you must press **Kernel > Restart.** This allows the installation to take effect. Once you see the blue **Connected/Kernel ready** button in the top right, you are good to go."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Import"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport matplotlib\nfrom surprise import Dataset, SVD, NormalPredictor, BaselineOnly, KNNBasic, NMF\nfrom surprise.model_selection import cross_validate, KFold",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dataSet = Dataset.load_builtin('ml-100k')",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Get raw data from the dataset.\nrawData = pd.read_table(dataSet.ratings_file, names=['user', 'item', 'rating', 'timestamp'])\n\n# Extract ratings.\nratings = rawData.rating\n\n# Show the data with pandas' tools.\nprint(\"Total entries:\")\nprint(ratings.count())\nprint(\"\\nRatings count:\")\nprint(ratings.value_counts().sort_index())\nratings.hist(bins=5, grid=0)",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Total entries:\n100000\n\nRatings count:\n1     6110\n2    11370\n3    27145\n4    34174\n5    21201\nName: rating, dtype: int64\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x7fd8b6d7c438>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Model 1: Random"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "normalModel = NormalPredictor()",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Train on data using cross-validation with k=5 folds, measuring the RMSE\ncross_validate(normalModel, dataSet, measures=['RMSE'], cv=5, verbose=True)",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Evaluating RMSE of algorithm NormalPredictor on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    1.5343  1.5223  1.5163  1.5223  1.5265  1.5244  0.0060  \nFit time          0.17    0.18    0.16    0.18    0.19    0.18    0.01    \nTest time         0.29    0.19    0.17    0.29    0.24    0.24    0.05    \n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "{'test_rmse': array([1.53433907, 1.52228385, 1.51634454, 1.52225897, 1.5265337 ]),\n 'fit_time': (0.16830825805664062,\n  0.18152475357055664,\n  0.1552743911743164,\n  0.18437886238098145,\n  0.19203639030456543),\n 'test_time': (0.29009509086608887,\n  0.18946504592895508,\n  0.17206120491027832,\n  0.29299306869506836,\n  0.23724031448364258)}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Model 2: User-Based Collaborative Filtering"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "userFilteringModel = KNNBasic(sim_options={'name': 'cosine', 'user_based': True})",
      "execution_count": 44,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cross_validate(userFilteringModel, dataSet, measures=['RMSE'], cv=5, verbose=True)",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Computing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nEvaluating RMSE of algorithm KNNBasic on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    1.0193  1.0187  1.0125  1.0110  1.0227  1.0168  0.0044  \nFit time          1.30    1.32    1.45    1.24    1.34    1.33    0.07    \nTest time         5.06    6.55    5.58    5.22    5.26    5.53    0.54    \n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": "{'test_rmse': array([1.0193222 , 1.0187437 , 1.01245071, 1.01101729, 1.02268412]),\n 'fit_time': (1.3016605377197266,\n  1.3229217529296875,\n  1.450211763381958,\n  1.2359185218811035,\n  1.3403871059417725),\n 'test_time': (5.057806968688965,\n  6.55403208732605,\n  5.579775333404541,\n  5.216059923171997,\n  5.2554662227630615)}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Model 3: Item-Based Collaborative Filtering"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "itemFilteringModel = KNNBasic(sim_options={'name': 'cosine', 'user_based': False})",
      "execution_count": 48,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cross_validate(itemFilteringModel, dataSet, measures=['RMSE'], cv=5, verbose=True)",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Computing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nEvaluating RMSE of algorithm KNNBasic on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    1.0330  1.0229  1.0228  1.0330  1.0203  1.0264  0.0055  \nFit time          6.33    3.58    2.51    3.03    2.82    3.65    1.38    \nTest time         5.38    5.94    6.01    5.64    5.90    5.77    0.23    \n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": "{'test_rmse': array([1.0329836 , 1.02287555, 1.02279279, 1.03301697, 1.02029478]),\n 'fit_time': (6.325323820114136,\n  3.5762929916381836,\n  2.507969617843628,\n  3.0258467197418213,\n  2.8205394744873047),\n 'test_time': (5.375450611114502,\n  5.937932252883911,\n  6.008522272109985,\n  5.638849258422852,\n  5.902042627334595)}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Model 4: Matrix Factorization"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "SVDModel = SVD()",
      "execution_count": 50,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cross_validate(SVDModel, dataSet, measures=['RMSE'], cv=5, verbose=True)",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Evaluating RMSE of algorithm SVD on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    0.9417  0.9397  0.9378  0.9365  0.9347  0.9381  0.0024  \nFit time          7.09    6.33    8.60    7.13    7.56    7.34    0.74    \nTest time         0.26    0.33    0.20    0.27    0.21    0.25    0.05    \n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": "{'test_rmse': array([0.94173009, 0.93974565, 0.93775881, 0.93653856, 0.93474271]),\n 'fit_time': (7.089351177215576,\n  6.330826282501221,\n  8.602913618087769,\n  7.130563497543335,\n  7.556233167648315),\n 'test_time': (0.2551112174987793,\n  0.3333096504211426,\n  0.19997525215148926,\n  0.26703786849975586,\n  0.21363019943237305)}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Precision and Recall @ `k`"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n    '''Return precision and recall at k metrics for each user.'''\n\n    # First map the predictions to each user.\n    user_est_true = dict()\n    for uid, _, true_r, est, _ in predictions:\n        current = user_est_true.get(uid, list())\n        current.append((est, true_r))\n        user_est_true[uid] = current\n\n    precisions = dict()\n    recalls = dict()\n    for uid, user_ratings in user_est_true.items():\n\n        # Sort user ratings by estimated value\n        user_ratings.sort(key=lambda x: x[0], reverse=True)\n\n        # Number of relevant items\n        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n\n        # Number of recommended items in top k\n        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n\n        # Number of relevant and recommended items in top k\n        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n                              for (est, true_r) in user_ratings[:k])\n\n        # Precision@K: Proportion of recommended items that are relevant\n        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n\n        # Recall@K: Proportion of relevant items that are recommended\n        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n\n    return precisions, recalls",
      "execution_count": 52,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "models = {\n    'Normal model': normalModel,\n    'User collaborative filtering': userFilteringModel,\n    'Item collaborative filtering': itemFilteringModel,\n    'Matrix factorization (SVD)': SVDModel\n}\n\nkf = KFold(n_splits=5)\n\nfor k in [5, 10]:\n    for modelLabel, model in models.items():\n        print(f'Runing calculation for: k={k} and model={modelLabel}')\n        precision = []\n        recall = []\n        for trainSet, testSet in kf.split(dataSet):\n            model.fit(trainSet)\n            predictions = model.test(testSet, verbose=False)\n            precisions, recalls = precision_recall_at_k(predictions, k=k, threshold=3.5)\n            precision.append(sum(prec for prec in precisions.values()) / len(precisions))\n            recall.append(sum(rec for rec in recalls.values()) / len(recalls))\n        avg_precision = sum(precision) / len(precision)\n        avg_recall = sum(recall) / len(recall)\n        f1_score = 2 * avg_precision * avg_recall / (avg_precision + avg_recall)\n        print(' --> Precision: ', avg_precision)\n        print(' --> Recall: ', avg_recall)\n        print(' --> F1 score: ', f1_score)\n        print('\\n\\n ------------ \\n\\n')\n        ",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Runing calculation for: k=5 and model=Normal model\n --> Precision:  0.5867919021905001\n --> Recall:  0.338879702687486\n --> F1 score:  0.4296380364393957\n\n\n ------------ \n\n\nRuning calculation for: k=5 and model=User collaborative filtering\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\n --> Precision:  0.7557938774315661\n --> Recall:  0.45706476145697106\n --> F1 score:  0.5696405784196997\n\n\n ------------ \n\n\nRuning calculation for: k=5 and model=Item collaborative filtering\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\n --> Precision:  0.7935273236437267\n --> Recall:  0.3605209355656773\n --> F1 score:  0.4957907276996361\n\n\n ------------ \n\n\nRuning calculation for: k=5 and model=Matrix factorization (SVD)\n --> Precision:  0.7840823362866929\n --> Recall:  0.4321979771864445\n --> F1 score:  0.5572379918294462\n\n\n ------------ \n\n\nRuning calculation for: k=10 and model=Normal model\n --> Precision:  0.587651410805493\n --> Recall:  0.4364244905869697\n --> F1 score:  0.500871990552221\n\n\n ------------ \n\n\nRuning calculation for: k=10 and model=User collaborative filtering\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\n --> Precision:  0.7254014225514162\n --> Recall:  0.5954930719890935\n --> F1 score:  0.6540590839401874\n\n\n ------------ \n\n\nRuning calculation for: k=10 and model=Item collaborative filtering\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\n --> Precision:  0.7719943198158861\n --> Recall:  0.5117106299907495\n --> F1 score:  0.6154649474581705\n\n\n ------------ \n\n\nRuning calculation for: k=10 and model=Matrix factorization (SVD)\n --> Precision:  0.759511050271794\n --> Recall:  0.5608037252926057\n --> F1 score:  0.645204665245445\n\n\n ------------ \n\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Precision and recall are different from the RMSE as long they are about how the items are clasified, not about estimated diferences on avarages. Also between Precission and Recall there is a tread-off, even the performance evaluation of two metrics can be done with it's harmonic mean, called F1 score.<br />\n\nWhat is interesting of these results is that precision of the item filtering is better thant the user one, even better thant the SVD. Also is relevant that even the RMSE was better for SVD, the F1 score fo the user filtering is better than SVD. That means that the avarage of error of SVD is less but user filtering classify properly more elements than SVD."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#  Top-`n` Predictions"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_top_n(predictions, n=10):\n    '''Return the top-N recommendation for each user from a set of predictions.\n\n    Args:\n        predictions(list of Prediction objects): The list of predictions, as\n            returned by the test method of an algorithm.\n        n(int): The number of recommendation to output for each user. Default\n            is 10.\n\n    Returns:\n    A dict where keys are user (raw) ids and values are lists of tuples:\n        [(raw item id, rating estimation), ...] of size n.\n    '''\n\n    # First map the predictions to each user.\n    top_n = dict()\n    for uid, iid, true_r, est, _ in predictions:\n        current = top_n.get(uid, [])\n        current.append((iid, est))\n        top_n[uid] = current\n\n    # Then sort the predictions for each user and retrieve the k highest ones.\n    for uid, user_ratings in top_n.items():\n        user_ratings.sort(key=lambda x: x[1], reverse=True)\n        top_n[uid] = user_ratings[:n]\n\n    return top_n",
      "execution_count": 68,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "trainSet = dataSet.build_full_trainset()\ntestSet = trainSet.build_anti_testset()",
      "execution_count": 70,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Use the function and hints above to give the top-n predictions for a given user, for a reasonable value of n\nfor modelLabel, model in models.items():\n    model.fit(trainSet)\n    predictions = model.test(testSet)\n    top5 = get_top_n(predictions, n=5)\n    sample_user = list(top5)[0]\n    print(f' >>> model={modelLabel}, user={sample_user}: {top5[sample_user]}')",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": " >>> model=Normal model, user=196: [('302', 5), ('377', 5), ('40', 5), ('16', 5), ('304', 5)]\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\n >>> model=User collaborative filtering, user=196: [('1189', 5), ('1500', 5), ('814', 5), ('1536', 5), ('1293', 5)]\nComputing the cosine similarity matrix...\nDone computing similarity matrix.\n >>> model=Item collaborative filtering, user=196: [('1309', 4.5), ('1310', 4.5), ('1676', 4.25), ('1675', 4.25), ('1593', 4.090909090909091)]\n >>> model=Matrix factorization (SVD), user=196: [('64', 4.601494666395112), ('408', 4.531584913170746), ('169', 4.516175120144184), ('654', 4.4319148622941595), ('132', 4.413640402764078)]\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}